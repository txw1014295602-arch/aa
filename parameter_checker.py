#!/usr/bin/env python3
"""
å‚æ•°æ ¸æŸ¥ç³»ç»Ÿ - é‡æ–°è®¾è®¡ç‰ˆæœ¬
æ”¯æŒåŒåˆ†è¡¨ç»“æ„ã€å¤æ‚æ¡ä»¶è¡¨è¾¾å¼ã€åµŒå¥—éªŒè¯è§„åˆ™
Parameter Checker System - Redesigned Version
Supports dual-table structure, complex condition expressions, nested validation rules
"""

import pandas as pd
import logging
import re
from typing import Dict, List, Any, Optional, Set, Tuple
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('parameter_checker.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class ParameterChecker:
    """
    å‚æ•°æ ¸æŸ¥å™¨ç±» - æ”¯æŒåŒåˆ†è¡¨ç»“æ„å’Œå¤æ‚åµŒå¥—éªŒè¯
    """

    def __init__(self, knowledge_file="å‚æ•°çŸ¥è¯†åº“.xlsx"):
        """åˆå§‹åŒ–å‚æ•°æ ¸æŸ¥å™¨"""
        self.knowledge_file = knowledge_file
        self.parameter_info: Dict[str, Dict[str, Any]] = {}  # å‚æ•°ä¿¡æ¯è¡¨
        self.validation_rules: Dict[str, Dict[str, Any]] = {}  # éªŒè¯è§„åˆ™è¡¨
        
        # åŠ è½½çŸ¥è¯†åº“
        self.load_knowledge_base(knowledge_file)

    def load_knowledge_base(self, file_path: str) -> bool:
        """åŠ è½½åŒåˆ†è¡¨çŸ¥è¯†åº“"""
        try:
            # åŠ è½½å‚æ•°ä¿¡æ¯è¡¨
            param_success = self.load_parameter_info(file_path, "å‚æ•°ä¿¡æ¯")
            # åŠ è½½éªŒè¯è§„åˆ™è¡¨
            rule_success = self.load_validation_rules(file_path, "éªŒè¯è§„åˆ™")
            
            if param_success and rule_success:
                logger.info(f"çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {len(self.parameter_info)}ä¸ªå‚æ•°, {len(self.validation_rules)}ä¸ªéªŒè¯è§„åˆ™")
                return True
            else:
                logger.warning("çŸ¥è¯†åº“åŠ è½½éƒ¨åˆ†å¤±è´¥")
                return False
                
        except FileNotFoundError:
            logger.info(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼Œæ­£åœ¨ç”Ÿæˆç¤ºä¾‹æ–‡ä»¶...")
            # ç”Ÿæˆç¤ºä¾‹æ–‡ä»¶
            self.create_sample_excel()
            # é‡æ–°åŠ è½½
            try:
                param_success = self.load_parameter_info(file_path, "å‚æ•°ä¿¡æ¯")
                rule_success = self.load_validation_rules(file_path, "éªŒè¯è§„åˆ™")
                if param_success and rule_success:
                    logger.info(f"ç¤ºä¾‹çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {len(self.parameter_info)}ä¸ªå‚æ•°, {len(self.validation_rules)}ä¸ªéªŒè¯è§„åˆ™")
                    return True
            except Exception as e:
                logger.error(f"é‡æ–°åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
            return False
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
            return False

    def load_parameter_info(self, file_path: str, sheet_name: str) -> bool:
        """åŠ è½½å‚æ•°ä¿¡æ¯è¡¨"""
        try:
            df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)
            
            # éªŒè¯å¿…è¦åˆ—
            required_columns = ['MOåç§°', 'MOæè¿°', 'åœºæ™¯ç±»å‹', 'å‚æ•°åç§°', 'å‚æ•°ID', 'å‚æ•°ç±»å‹', 'å‚æ•°å«ä¹‰', 'å€¼æè¿°']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                logger.error(f"å‚æ•°ä¿¡æ¯è¡¨ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                return False

            self.parameter_info = {}
            
            # æŒ‰MOåç§°å’Œå‚æ•°åç§°åˆ†ç»„
            for (mo_name, param_name), group in df.groupby(['MOåç§°', 'å‚æ•°åç§°'], dropna=False):
                # ä½¿ç”¨ç¬¬ä¸€è¡Œçš„ä¿¡æ¯
                row = group.iloc[0]
                
                # åˆå§‹åŒ–MOä¿¡æ¯
                if mo_name not in self.parameter_info:
                    self.parameter_info[mo_name] = {
                        'mo_description': str(row.get('MOæè¿°', '')).strip(),
                        'scenario': str(row.get('åœºæ™¯ç±»å‹', '')).strip(),
                        'parameters': {}
                    }
                
                # æ·»åŠ å‚æ•°ä¿¡æ¯
                param_type = str(row.get('å‚æ•°ç±»å‹', 'single')).strip()
                self.parameter_info[mo_name]['parameters'][param_name] = {
                    'parameter_id': str(row.get('å‚æ•°ID', '')).strip(),
                    'parameter_type': param_type,
                    'parameter_description': str(row.get('å‚æ•°å«ä¹‰', '')).strip(),
                    'value_description': str(row.get('å€¼æè¿°', '')).strip()
                }
            
            logger.info(f"å‚æ•°ä¿¡æ¯è¡¨åŠ è½½æˆåŠŸ: {len(self.parameter_info)} ä¸ªMO")
            return True
            
        except FileNotFoundError:
            raise  # é‡æ–°æŠ›å‡ºFileNotFoundErrorè®©ä¸Šå±‚å¤„ç†
        except Exception as e:
            logger.error(f"åŠ è½½å‚æ•°ä¿¡æ¯è¡¨å¤±è´¥: {str(e)}")
            return False

    def load_validation_rules(self, file_path: str, sheet_name: str) -> bool:
        """åŠ è½½éªŒè¯è§„åˆ™è¡¨"""
        try:
            df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)
            
            # éªŒè¯å¿…è¦åˆ—
            required_columns = ['æ ¡éªŒID', 'æ ¡éªŒç±»å‹', 'MOåç§°', 'æ¡ä»¶è¡¨è¾¾å¼', 'æœŸæœ›å€¼è¡¨è¾¾å¼', 'é”™è¯¯æè¿°', 'ç»§ç»­æ ¡éªŒID']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                logger.error(f"éªŒè¯è§„åˆ™è¡¨ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                return False

            self.validation_rules = {}
            
            for _, row in df.iterrows():
                rule_id = str(row.get('æ ¡éªŒID', '')).strip()
                if not rule_id or rule_id == 'nan':
                    continue
                    
                self.validation_rules[rule_id] = {
                    'rule_id': rule_id,
                    'check_type': str(row.get('æ ¡éªŒç±»å‹', '')).strip(),
                    'mo_name': str(row.get('MOåç§°', '')).strip(),
                    'condition_expression': str(row.get('æ¡ä»¶è¡¨è¾¾å¼', '')).strip(),
                    'expected_expression': str(row.get('æœŸæœ›å€¼è¡¨è¾¾å¼', '')).strip(),
                    'error_description': str(row.get('é”™è¯¯æè¿°', '')).strip(),
                    'next_check_id': str(row.get('ç»§ç»­æ ¡éªŒID', '')).strip() if str(row.get('ç»§ç»­æ ¡éªŒID', '')).strip() != 'nan' else None
                }
            
            logger.info(f"éªŒè¯è§„åˆ™è¡¨åŠ è½½æˆåŠŸ: {len(self.validation_rules)} ä¸ªè§„åˆ™")
            return True
            
        except FileNotFoundError:
            raise  # é‡æ–°æŠ›å‡ºFileNotFoundErrorè®©ä¸Šå±‚å¤„ç†
        except Exception as e:
            logger.error(f"åŠ è½½éªŒè¯è§„åˆ™è¡¨å¤±è´¥: {str(e)}")
            return False

    def parse_condition_expression(self, expression: str, data_row: Dict[str, Any]) -> bool:
        """
        è§£æå¤æ‚æ¡ä»¶è¡¨è¾¾å¼
        æ”¯æŒæ ¼å¼: (å‚æ•°å1=å€¼1andå‚æ•°å2=å€¼2)or(å‚æ•°å3>å€¼3andå‚æ•°å2!=å€¼2)
        """
        if not expression or expression == 'nan':
            return True
            
        try:
            # æ›¿æ¢ä¸­æ–‡é€»è¾‘è¿ç®—ç¬¦
            expression = expression.replace('and', ' and ').replace('or', ' or ')
            expression = expression.replace('ä¸”', ' and ').replace('æˆ–', ' or ')
            
            # è§£æå•ä¸ªæ¡ä»¶
            def evaluate_single_condition(cond: str) -> bool:
                cond = cond.strip()
                
                # æ”¯æŒçš„è¿ç®—ç¬¦
                operators = ['>=', '<=', '!=', '=', '>', '<']
                
                for op in operators:
                    if op in cond:
                        parts = cond.split(op, 1)
                        if len(parts) == 2:
                            param_name = parts[0].strip()
                            expected_value = parts[1].strip()
                            
                            # è·å–å®é™…å€¼
                            actual_value = str(data_row.get(param_name, '')).strip()
                            
                            # æ‰§è¡Œæ¯”è¾ƒ
                            return self._compare_values(actual_value, op, expected_value)
                
                logger.warning(f"æ— æ³•è§£ææ¡ä»¶: {cond}")
                return False
            
            # å¤„ç†æ‹¬å·å’Œé€»è¾‘è¿ç®—ç¬¦
            # ç®€åŒ–å¤„ç†ï¼šå…ˆæ›¿æ¢æ‹¬å·å†…çš„æ¡ä»¶
            def evaluate_expression(expr: str) -> bool:
                # å¤„ç†æ‹¬å·
                while '(' in expr:
                    # æ‰¾åˆ°æœ€å†…å±‚æ‹¬å·
                    start = expr.rfind('(')
                    end = expr.find(')', start)
                    if end == -1:
                        break
                    
                    # è¯„ä¼°æ‹¬å·å†…çš„è¡¨è¾¾å¼
                    inner_expr = expr[start+1:end]
                    result = self._evaluate_simple_expression(inner_expr, evaluate_single_condition)
                    
                    # æ›¿æ¢æ‹¬å·
                    expr = expr[:start] + str(result) + expr[end+1:]
                
                # è¯„ä¼°å‰©ä½™è¡¨è¾¾å¼
                return self._evaluate_simple_expression(expr, evaluate_single_condition)
            
            return evaluate_expression(expression)
            
        except Exception as e:
            logger.error(f"è§£ææ¡ä»¶è¡¨è¾¾å¼å¤±è´¥: {expression}, é”™è¯¯: {str(e)}")
            return False

    def _evaluate_simple_expression(self, expr: str, eval_func) -> bool:
        """è¯„ä¼°ç®€å•è¡¨è¾¾å¼ï¼ˆä¸å«æ‹¬å·ï¼‰"""
        expr = expr.strip()
        
        # å¤„ç† or è¿ç®—ç¬¦
        if ' or ' in expr:
            parts = expr.split(' or ')
            return any(self._evaluate_simple_expression(part.strip(), eval_func) for part in parts)
        
        # å¤„ç† and è¿ç®—ç¬¦
        if ' and ' in expr:
            parts = expr.split(' and ')
            return all(self._evaluate_simple_expression(part.strip(), eval_func) for part in parts)
        
        # å¤„ç†å¸ƒå°”å€¼
        if expr.lower() == 'true':
            return True
        elif expr.lower() == 'false':
            return False
        
        # å•ä¸ªæ¡ä»¶
        return eval_func(expr)

    def _compare_values(self, actual: str, operator: str, expected: str) -> bool:
        """æ¯”è¾ƒä¸¤ä¸ªå€¼"""
        try:
            # å°è¯•æ•°å€¼æ¯”è¾ƒ
            try:
                actual_num = float(actual)
                expected_num = float(expected)
                
                if operator == '=':
                    return actual_num == expected_num
                elif operator == '!=':
                    return actual_num != expected_num
                elif operator == '>':
                    return actual_num > expected_num
                elif operator == '<':
                    return actual_num < expected_num
                elif operator == '>=':
                    return actual_num >= expected_num
                elif operator == '<=':
                    return actual_num <= expected_num
            except ValueError:
                # å­—ç¬¦ä¸²æ¯”è¾ƒ
                if operator == '=':
                    return actual == expected
                elif operator == '!=':
                    return actual != expected
                else:
                    # å­—ç¬¦ä¸²ä¸æ”¯æŒå¤§å°æ¯”è¾ƒ
                    logger.warning(f"å­—ç¬¦ä¸²ä¸æ”¯æŒè¿ç®—ç¬¦ {operator}: {actual} {operator} {expected}")
                    return False
                    
        except Exception as e:
            logger.error(f"å€¼æ¯”è¾ƒå¤±è´¥: {actual} {operator} {expected}, é”™è¯¯: {str(e)}")
            return False
        
        return False

    def parse_expected_expression(self, expression: str) -> List[Dict[str, Any]]:
        """
        è§£ææœŸæœ›å€¼è¡¨è¾¾å¼
        æ”¯æŒæ ¼å¼: å‚æ•°å1=å€¼1,å‚æ•°å2=å€¼2 æˆ– å‚æ•°å1=k1:å¼€&k2:å…³&k3:å¼€
        """
        expected_params = []
        
        if not expression or expression == 'nan':
            return expected_params
        
        # æŒ‰é€—å·åˆ†å‰²å¤šä¸ªå‚æ•°
        param_expressions = [expr.strip() for expr in expression.split(',') if expr.strip()]
        
        for param_expr in param_expressions:
            if '=' in param_expr:
                param_name, param_value = param_expr.split('=', 1)
                param_name = param_name.strip()
                param_value = param_value.strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¤šå€¼å‚æ•°ï¼ˆåŒ…å«å¼€å…³ç»„åˆï¼‰
                if '&' in param_value and ':' in param_value:
                    # å¤šå€¼å‚æ•°
                    switches = {}
                    for switch_expr in param_value.split('&'):
                        if ':' in switch_expr:
                            switch_name, switch_state = switch_expr.split(':', 1)
                            switches[switch_name.strip()] = switch_state.strip()
                    
                    expected_params.append({
                        'param_name': param_name,
                        'param_type': 'multiple',
                        'expected_switches': switches,
                        'expected_value': param_value
                    })
                else:
                    # å•å€¼å‚æ•°
                    expected_params.append({
                        'param_name': param_name,
                        'param_type': 'single',
                        'expected_value': param_value
                    })
        
        return expected_params

    def execute_validation_rule(self, rule_id: str, data_groups: Dict[str, pd.DataFrame], sector_id: str) -> List[Dict[str, Any]]:
        """æ‰§è¡Œå•ä¸ªéªŒè¯è§„åˆ™"""
        if rule_id not in self.validation_rules:
            logger.warning(f"éªŒè¯è§„åˆ™ {rule_id} ä¸å­˜åœ¨")
            return []
        
        rule = self.validation_rules[rule_id]
        errors = []
        
        logger.info(f"æ‰§è¡ŒéªŒè¯è§„åˆ™: {rule_id} ({rule['check_type']})")
        
        # æ ¹æ®æ ¡éªŒç±»å‹æ‰§è¡Œä¸åŒçš„éªŒè¯
        if rule['check_type'] == 'æ¼é…':
            errors.extend(self._check_missing_config(rule, data_groups, sector_id))
        elif rule['check_type'] == 'é”™é…':
            errors.extend(self._check_incorrect_config(rule, data_groups, sector_id))
        else:
            logger.warning(f"æœªçŸ¥çš„æ ¡éªŒç±»å‹: {rule['check_type']}")
        
        # å¦‚æœå½“å‰è§„åˆ™é€šè¿‡ä¸”æœ‰ç»§ç»­æ ¡éªŒï¼Œæ‰§è¡Œç»§ç»­æ ¡éªŒ
        if not errors and rule['next_check_id']:
            logger.info(f"è§„åˆ™ {rule_id} é€šè¿‡ï¼Œç»§ç»­æ‰§è¡Œ: {rule['next_check_id']}")
            errors.extend(self.execute_validation_rule(rule['next_check_id'], data_groups, sector_id))
        elif errors:
            logger.info(f"è§„åˆ™ {rule_id} æ£€æŸ¥å¤±è´¥ï¼Œä¸ç»§ç»­åç»­éªŒè¯")
        
        return errors

    def _check_missing_config(self, rule: Dict[str, Any], data_groups: Dict[str, pd.DataFrame], sector_id: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æ¼é…"""
        mo_name = rule['mo_name']
        condition_expr = rule['condition_expression']
        expected_expr = rule['expected_expression']
        
        errors = []
        
        if mo_name not in data_groups:
            errors.append({
                'sector_id': sector_id,
                'rule_id': rule['rule_id'],
                'mo_name': mo_name,
                'check_type': 'æ¼é…',
                'error_type': 'æ•°æ®ä¸å­˜åœ¨',
                'message': f'{mo_name}æ•°æ®ä¸å­˜åœ¨',
                'error_description': rule['error_description']
            })
            return errors
        
        mo_data = data_groups[mo_name]
        expected_params = self.parse_expected_expression(expected_expr)
        
        if not expected_params:
            logger.warning(f"è§„åˆ™ {rule['rule_id']} æ²¡æœ‰æœ‰æ•ˆçš„æœŸæœ›å€¼è¡¨è¾¾å¼")
            return errors
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¬¦åˆæ¡ä»¶çš„è®°å½•
        found_matching_record = False
        
        for _, row in mo_data.iterrows():
            row_dict = row.to_dict()
            row_dict = {k: str(v).strip() for k, v in row_dict.items()}
            
            # æ£€æŸ¥æ¡ä»¶è¡¨è¾¾å¼
            if not self.parse_condition_expression(condition_expr, row_dict):
                continue
            
            # æ£€æŸ¥æœŸæœ›å€¼
            all_params_match = True
            for expected_param in expected_params:
                param_name = expected_param['param_name']
                
                if param_name not in row_dict:
                    all_params_match = False
                    break
                
                if expected_param['param_type'] == 'multiple':
                    # å¤šå€¼å‚æ•°æ£€æŸ¥
                    actual_value = row_dict[param_name]
                    if not self._check_multi_value_match(actual_value, expected_param['expected_switches']):
                        all_params_match = False
                        break
                else:
                    # å•å€¼å‚æ•°æ£€æŸ¥
                    if row_dict[param_name] != expected_param['expected_value']:
                        all_params_match = False
                        break
            
            if all_params_match:
                found_matching_record = True
                break
        
        if not found_matching_record:
            param_names = [p['param_name'] for p in expected_params]
            errors.append({
                'sector_id': sector_id,
                'rule_id': rule['rule_id'],
                'mo_name': mo_name,
                'param_names': param_names,
                'check_type': 'æ¼é…',
                'error_type': 'æ¼é…',
                'message': f'æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é…ç½®è®°å½•',
                'condition': condition_expr,
                'expected_expression': expected_expr,
                'error_description': rule['error_description']
            })
        
        return errors

    def _check_incorrect_config(self, rule: Dict[str, Any], data_groups: Dict[str, pd.DataFrame], sector_id: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥é”™é…"""
        mo_name = rule['mo_name']
        condition_expr = rule['condition_expression']
        expected_expr = rule['expected_expression']
        
        errors = []
        
        if mo_name not in data_groups:
            return errors  # æ•°æ®ä¸å­˜åœ¨æ—¶ä¸æŠ¥é”™é…é”™è¯¯
        
        mo_data = data_groups[mo_name]
        expected_params = self.parse_expected_expression(expected_expr)
        
        if not expected_params:
            logger.warning(f"è§„åˆ™ {rule['rule_id']} æ²¡æœ‰æœ‰æ•ˆçš„æœŸæœ›å€¼è¡¨è¾¾å¼")
            return errors
        
        # æ£€æŸ¥æ¯æ¡è®°å½•
        for idx, row in mo_data.iterrows():
            row_dict = row.to_dict()
            row_dict = {k: str(v).strip() for k, v in row_dict.items()}
            
            # æ£€æŸ¥æ¡ä»¶è¡¨è¾¾å¼
            if not self.parse_condition_expression(condition_expr, row_dict):
                continue
            
            # æ£€æŸ¥æœŸæœ›å€¼
            for expected_param in expected_params:
                param_name = expected_param['param_name']
                
                if param_name not in row_dict:
                    continue
                
                if expected_param['param_type'] == 'multiple':
                    # å¤šå€¼å‚æ•°æ£€æŸ¥
                    actual_value = row_dict[param_name]
                    if not self._check_multi_value_match(actual_value, expected_param['expected_switches']):
                        errors.append({
                            'sector_id': sector_id,
                            'rule_id': rule['rule_id'],
                            'mo_name': mo_name,
                            'param_name': param_name,
                            'check_type': 'é”™é…',
                            'error_type': 'é”™é…',
                            'message': f'{param_name}é…ç½®é”™è¯¯',
                            'current_value': actual_value,
                            'expected_value': expected_param['expected_value'],
                            'condition': condition_expr,
                            'error_description': rule['error_description'],
                            'row_index': idx
                        })
                else:
                    # å•å€¼å‚æ•°æ£€æŸ¥
                    if row_dict[param_name] != expected_param['expected_value']:
                        errors.append({
                            'sector_id': sector_id,
                            'rule_id': rule['rule_id'],
                            'mo_name': mo_name,
                            'param_name': param_name,
                            'check_type': 'é”™é…',
                            'error_type': 'é”™é…',
                            'message': f'{param_name}é…ç½®é”™è¯¯',
                            'current_value': row_dict[param_name],
                            'expected_value': expected_param['expected_value'],
                            'condition': condition_expr,
                            'error_description': rule['error_description'],
                            'row_index': idx
                        })
        
        return errors

    def _check_multi_value_match(self, actual_value: str, expected_switches: Dict[str, str]) -> bool:
        """æ£€æŸ¥å¤šå€¼å‚æ•°æ˜¯å¦åŒ¹é…"""
        if not actual_value or not expected_switches:
            return False
        
        # è§£æå®é™…å€¼ä¸­çš„å¼€å…³çŠ¶æ€
        actual_switches = {}
        for switch_expr in actual_value.split('&'):
            if ':' in switch_expr:
                switch_name, switch_state = switch_expr.split(':', 1)
                actual_switches[switch_name.strip()] = switch_state.strip()
        
        # æ£€æŸ¥æ¯ä¸ªæœŸæœ›çš„å¼€å…³çŠ¶æ€
        for switch_name, expected_state in expected_switches.items():
            if switch_name not in actual_switches:
                return False
            if actual_switches[switch_name] != expected_state:
                return False
        
        return True

    def validate_sector_data(self, data_groups: Dict[str, pd.DataFrame], sector_id: str) -> List[Dict[str, Any]]:
        """éªŒè¯æ‰‡åŒºæ•°æ®"""
        all_errors = []
        
        # æ‰¾åˆ°æ‰€æœ‰å…¥å£éªŒè¯è§„åˆ™ï¼ˆæ²¡æœ‰è¢«å…¶ä»–è§„åˆ™å¼•ç”¨çš„è§„åˆ™ï¼‰
        referenced_rules = set()
        for rule in self.validation_rules.values():
            if rule['next_check_id']:
                referenced_rules.add(rule['next_check_id'])
        
        entry_rules = [rule_id for rule_id in self.validation_rules.keys() 
                      if rule_id not in referenced_rules]
        
        logger.info(f"å‘ç° {len(entry_rules)} ä¸ªå…¥å£éªŒè¯è§„åˆ™: {entry_rules}")
        
        # æ‰§è¡Œæ¯ä¸ªå…¥å£è§„åˆ™
        for rule_id in entry_rules:
            errors = self.execute_validation_rule(rule_id, data_groups, sector_id)
            all_errors.extend(errors)
        
        return all_errors

    def create_sample_excel(self) -> None:
        """åˆ›å»ºç¤ºä¾‹Excelæ–‡ä»¶"""
        logger.info("æ­£åœ¨ç”Ÿæˆç¤ºä¾‹å‚æ•°çŸ¥è¯†åº“...")
        
        wb = Workbook()
        
        # åˆ é™¤é»˜è®¤å·¥ä½œè¡¨
        wb.remove(wb.active)
        
        # åˆ›å»ºå‚æ•°ä¿¡æ¯è¡¨
        self._create_parameter_info_sheet(wb)
        
        # åˆ›å»ºéªŒè¯è§„åˆ™è¡¨
        self._create_validation_rules_sheet(wb)
        
        # ä¿å­˜æ–‡ä»¶
        wb.save(self.knowledge_file)
        logger.info(f"ç¤ºä¾‹å‚æ•°çŸ¥è¯†åº“å·²ç”Ÿæˆ: {self.knowledge_file}")

    def _create_parameter_info_sheet(self, wb: Workbook) -> None:
        """åˆ›å»ºå‚æ•°ä¿¡æ¯è¡¨"""
        ws = wb.create_sheet("å‚æ•°ä¿¡æ¯")
        
        # è®¾ç½®è¡¨å¤´
        headers = ['MOåç§°', 'MOæè¿°', 'åœºæ™¯ç±»å‹', 'å‚æ•°åç§°', 'å‚æ•°ID', 'å‚æ•°ç±»å‹', 'å‚æ•°å«ä¹‰', 'å€¼æè¿°']
        ws.append(headers)
        
        # è®¾ç½®è¡¨å¤´æ ·å¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_num)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center")
        
        # æ·»åŠ ç¤ºä¾‹æ•°æ®
        sample_data = [
            # NRCELLå‚æ•°
            ["NRCELL", "5Gå°åŒºå¯¹è±¡", "5GåŸºç¡€é…ç½®", "è·Ÿè¸ªåŒºç ", "tac", "single", "æ ‡è¯†å°åŒºæ‰€å±çš„è·Ÿè¸ªåŒº", ""],
            ["NRCELL", "5Gå°åŒºå¯¹è±¡", "5GåŸºç¡€é…ç½®", "å°åŒºçŠ¶æ€", "cellState", "single", "å°åŒºçš„æ¿€æ´»çŠ¶æ€", ""],
            
            # NRDUCELLå‚æ•°
            ["NRDUCELL", "5G DUå°åŒºå¯¹è±¡", "5Gç‰©ç†å±‚é…ç½®", "å°åŒºåŠå¾„(ç±³)", "cellRadius", "single", "å°åŒºè¦†ç›–åŠå¾„", ""],
            ["NRDUCELL", "5G DUå°åŒºå¯¹è±¡", "5Gç‰©ç†å±‚é…ç½®", "æœ€å¤§ä¼ è¾“åŠŸç‡", "maxTxPower", "single", "å°åŒºæœ€å¤§å‘å°„åŠŸç‡", ""],
            
            # NRDUCELLBEAMå‚æ•°ï¼ˆå¤šå€¼å‚æ•°ï¼‰
            ["NRDUCELLBEAM", "5Gæ³¢æŸé…ç½®å¯¹è±¡", "5Gæ³¢æŸç®¡ç†", "æ³¢æŸå¼€å…³ç»„åˆ", "beamSwitchComb", "multiple", "æ³¢æŸå¼€å…³çŠ¶æ€ç»„åˆ", "beam1:ç¬¬ä¸€æ³¢æŸå¼€å…³,beam2:ç¬¬äºŒæ³¢æŸå¼€å…³,beam3:ç¬¬ä¸‰æ³¢æŸå¼€å…³"],
            
            # NRCELLFREQRELATIONå‚æ•°
            ["NRCELLFREQRELATION", "å°åŒºé¢‘ç‡å…³ç³»å¯¹è±¡", "é¢‘ç‡ç®¡ç†é…ç½®", "è¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§", "connectedFreqPriority", "single", "è¿æ¥æ€ä¸‹çš„é¢‘ç‡ä¼˜å…ˆçº§", ""],
        ]
        
        for row_data in sample_data:
            ws.append(row_data)
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[column_letter].width = adjusted_width

    def _create_validation_rules_sheet(self, wb: Workbook) -> None:
        """åˆ›å»ºéªŒè¯è§„åˆ™è¡¨"""
        ws = wb.create_sheet("éªŒè¯è§„åˆ™")
        
        # è®¾ç½®è¡¨å¤´
        headers = ['æ ¡éªŒID', 'æ ¡éªŒç±»å‹', 'MOåç§°', 'æ¡ä»¶è¡¨è¾¾å¼', 'æœŸæœ›å€¼è¡¨è¾¾å¼', 'é”™è¯¯æè¿°', 'ç»§ç»­æ ¡éªŒID']
        ws.append(headers)
        
        # è®¾ç½®è¡¨å¤´æ ·å¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_num)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center")
        
        # æ·»åŠ ç¤ºä¾‹éªŒè¯è§„åˆ™
        sample_rules = [
            # å¤æ‚åµŒå¥—éªŒè¯é“¾ç¤ºä¾‹
            ["MISS_001", "æ¼é…", "NRCELL", "", "è·Ÿè¸ªåŒºç =100", "ç¼ºå°‘è·Ÿè¸ªåŒºç ä¸º100çš„å°åŒºé…ç½®", "ERROR_001"],
            ["ERROR_001", "é”™é…", "NRDUCELL", "è·Ÿè¸ªåŒºç =100", "å°åŒºåŠå¾„(ç±³)=500", "è·Ÿè¸ªåŒºç ä¸º100çš„å°åŒºï¼ŒåŠå¾„åº”é…ç½®ä¸º500ç±³", "ERROR_002"],
            ["ERROR_002", "é”™é…", "NRDUCELL", "è·Ÿè¸ªåŒºç =100andå°åŒºåŠå¾„(ç±³)=500", "æœ€å¤§ä¼ è¾“åŠŸç‡=43", "åŠå¾„500ç±³çš„å°åŒºï¼ŒåŠŸç‡åº”ä¸º43dBm", "ERROR_003"],
            ["ERROR_003", "é”™é…", "NRDUCELLBEAM", "è·Ÿè¸ªåŒºç =100", "æ³¢æŸå¼€å…³ç»„åˆ=beam1:å¼€&beam2:å…³&beam3:å¼€", "è·Ÿè¸ªåŒºç 100çš„å°åŒºï¼Œæ³¢æŸç»„åˆåº”ä¸ºbeam1å¼€beam2å…³beam3å¼€", "MISS_002"],
            ["MISS_002", "æ¼é…", "NRCELLFREQRELATION", "è·Ÿè¸ªåŒºç =100", "è¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§=1", "ç¼ºå°‘è·Ÿè¸ªåŒºç 100å°åŒºçš„é¢‘ç‡ä¼˜å…ˆçº§é…ç½®", "ERROR_004"],
            ["ERROR_004", "é”™é…", "NRCELL", "è·Ÿè¸ªåŒºç =100andè¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§=1", "å°åŒºçŠ¶æ€=æ¿€æ´»", "å·²é…ç½®é¢‘ç‡ä¼˜å…ˆçº§çš„å°åŒºçŠ¶æ€åº”ä¸ºæ¿€æ´»", ""],
            
            # å¤æ‚æ¡ä»¶ç¤ºä¾‹
            ["COMPLEX_001", "é”™é…", "NRDUCELL", "(è·Ÿè¸ªåŒºç =200orè·Ÿè¸ªåŒºç =300)andå°åŒºçŠ¶æ€=æ¿€æ´»", "å°åŒºåŠå¾„(ç±³)=1000", "ç‰¹æ®Šè·Ÿè¸ªåŒºçš„æ¿€æ´»å°åŒºåŠå¾„åº”ä¸º1000ç±³", ""],
            ["COMPLEX_002", "æ¼é…", "NRCELL", "å°åŒºåŠå¾„(ç±³)>500andæœ€å¤§ä¼ è¾“åŠŸç‡>=40", "å°åŒºçŠ¶æ€=æ¿€æ´»", "å¤§åŠå¾„é«˜åŠŸç‡å°åŒºå¿…é¡»æ¿€æ´»", ""],
        ]
        
        for row_data in sample_rules:
            ws.append(row_data)
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 60)
            ws.column_dimensions[column_letter].width = adjusted_width

    def run_validation_example(self) -> None:
        """è¿è¡ŒéªŒè¯ç¤ºä¾‹"""
        logger.info("ğŸ§ª å¼€å§‹éªŒè¯ç¤ºä¾‹æµ‹è¯•...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            "NRCELL": pd.DataFrame([
                {
                    "f_site_id": "13566583",
                    "f_cell_id": "1",
                    "è·Ÿè¸ªåŒºç ": "200",  # ä¸ç¬¦åˆæœŸæœ›å€¼100
                    "å°åŒºçŠ¶æ€": "æ¿€æ´»",
                    "è¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§": "1"
                },
                {
                    "f_site_id": "13566583", 
                    "f_cell_id": "2",
                    "è·Ÿè¸ªåŒºç ": "100",  # ç¬¦åˆæœŸæœ›å€¼
                    "å°åŒºçŠ¶æ€": "éæ¿€æ´»",  # å¯èƒ½è§¦å‘åç»­é”™é…
                    "è¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§": "1"
                },
                {
                    "f_site_id": "13566583", 
                    "f_cell_id": "3",
                    "è·Ÿè¸ªåŒºç ": "300",  # ç”¨äºå¤æ‚æ¡ä»¶æµ‹è¯•
                    "å°åŒºçŠ¶æ€": "æ¿€æ´»",
                    "è¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§": "2"
                }
            ]),
            "NRDUCELL": pd.DataFrame([
                {
                    "f_site_id": "13566583",
                    "f_cell_id": "1",
                    "è·Ÿè¸ªåŒºç ": "200",
                    "å°åŒºåŠå¾„(ç±³)": "1200",  # ç”¨äºå¤æ‚æ¡ä»¶æµ‹è¯•
                    "æœ€å¤§ä¼ è¾“åŠŸç‡": "40",
                    "å°åŒºçŠ¶æ€": "æ¿€æ´»"
                },
                {
                    "f_site_id": "13566583",
                    "f_cell_id": "2",
                    "è·Ÿè¸ªåŒºç ": "100",
                    "å°åŒºåŠå¾„(ç±³)": "300",  # ä¸ç¬¦åˆæœŸæœ›çš„500
                    "æœ€å¤§ä¼ è¾“åŠŸç‡": "40",
                    "å°åŒºçŠ¶æ€": "éæ¿€æ´»"
                },
                {
                    "f_site_id": "13566583",
                    "f_cell_id": "3",
                    "è·Ÿè¸ªåŒºç ": "300",
                    "å°åŒºåŠå¾„(ç±³)": "800",  # ä¸ç¬¦åˆå¤æ‚æ¡ä»¶çš„æœŸæœ›1000
                    "æœ€å¤§ä¼ è¾“åŠŸç‡": "42",
                    "å°åŒºçŠ¶æ€": "æ¿€æ´»"
                }
            ]),
            "NRDUCELLBEAM": pd.DataFrame([
                {
                    "f_site_id": "13566583",
                    "f_cell_id": "2",
                    "è·Ÿè¸ªåŒºç ": "100",
                    "æ³¢æŸå¼€å…³ç»„åˆ": "beam1:å…³&beam2:å¼€&beam3:å…³"  # ä¸ç¬¦åˆæœŸæœ›çš„beam1:å¼€&beam2:å…³&beam3:å¼€
                }
            ]),
            "NRCELLFREQRELATION": pd.DataFrame([
                {
                    "f_site_id": "13566583",
                    "f_cell_id": "2",
                    "è·Ÿè¸ªåŒºç ": "100",
                    "è¿æ¥æ€é¢‘ç‡ä¼˜å…ˆçº§": "1"  # ç¬¦åˆæœŸæœ›
                }
            ])
        }
        
        # æ‰§è¡ŒéªŒè¯
        errors = self.validate_sector_data(test_data, "test_sector_001")
        
        # è¾“å‡ºç»“æœ
        if errors:
            logger.info(f"ğŸ” å‘ç° {len(errors)} ä¸ªéªŒè¯é—®é¢˜:")
            for i, error in enumerate(errors, 1):
                logger.info(f"   {i}. ã€{error['check_type']}ã€‘{error.get('rule_id', 'N/A')} - {error['mo_name']}")
                if 'param_name' in error:
                    logger.info(f"      å‚æ•°: {error['param_name']}")
                if 'param_names' in error:
                    logger.info(f"      å‚æ•°: {', '.join(error['param_names'])}")
                logger.info(f"      é”™è¯¯: {error['message']}")
                if 'current_value' in error and 'expected_value' in error:
                    logger.info(f"      æœŸæœ›å€¼: {error['expected_value']}")
                    logger.info(f"      å®é™…å€¼: {error['current_value']}")
                if error.get('error_description'):
                    logger.info(f"      è¯´æ˜: {error['error_description']}")
                logger.info("")
        else:
            logger.info("âœ… æ‰€æœ‰éªŒè¯è§„åˆ™éƒ½é€šè¿‡äº†")


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    try:
        logger.info("ğŸš€ å¯åŠ¨å‚æ•°æ ¸æŸ¥ç³»ç»Ÿ...")
        
        # åˆ›å»ºå‚æ•°æ ¸æŸ¥å™¨å®ä¾‹
        checker = ParameterChecker()
        
        # è¿è¡ŒéªŒè¯ç¤ºä¾‹
        checker.run_validation_example()
        
        logger.info("âœ¨ å‚æ•°æ ¸æŸ¥ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")
        logger.info("ğŸ“‹ ç³»ç»Ÿç‰¹æ€§:")
        logger.info("   â€¢ åŒåˆ†è¡¨è®¾è®¡ï¼šå‚æ•°ä¿¡æ¯ä¸éªŒè¯è§„åˆ™å®Œå…¨åˆ†ç¦»")
        logger.info("   â€¢ å¤æ‚æ¡ä»¶æ”¯æŒï¼š(param1=value1and param2=value2)or(param3>value3)")
        logger.info("   â€¢ åµŒå¥—éªŒè¯é“¾ï¼šæ”¯æŒæ¼é…â†”é”™é…æ— é™åµŒå¥—è°ƒç”¨") 
        logger.info("   â€¢ å¤šå€¼å‚æ•°å¤„ç†ï¼šbeam1:å¼€&beam2:å…³&beam3:å¼€æ ¼å¼")
        logger.info("   â€¢ æ™ºèƒ½æ¡ä»¶ç­›é€‰ï¼šå…ˆç­›é€‰ç¬¦åˆæ¡ä»¶çš„è¡Œå†è¿›è¡ŒéªŒè¯")
        
        return True
        
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        return False


if __name__ == "__main__":
    success = main()
    if not success:
        exit(1)